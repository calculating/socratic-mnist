{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Layer, MultiHeadAttention, Dense, Add, Conv2D, MaxPooling2D\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(xr, yr), (xe, ye) = mnist.load_data()\n",
    "xr, xe = xr / 255.0, xe / 255.0\n",
    "xr, xe = xr.reshape(-1, 28, 28, 1), xe.reshape(-1, 28, 28, 1)\n",
    "yr, ye = to_categorical(yr), to_categorical(ye)\n",
    "\n",
    "\n",
    "\n",
    "_, bs = plt.subplots(1, 5, figsize=(4, 4))\n",
    "for b in bs:\n",
    "    index = randint(0, len(xr))\n",
    "    b.imshow(xr[index], cmap='gray')\n",
    "    b.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 980)\n"
     ]
    }
   ],
   "source": [
    "class fh(Sequential):\n",
    "    def __init__(self, cn):\n",
    "        super().__init__(\n",
    "            [\n",
    "                Conv2D(cn, 3, activation=\"relu\", padding=\"same\", name=\"fcv\"),\n",
    "                MaxPooling2D(2),\n",
    "                Conv2D(cn, 3, activation=\"relu\", padding=\"same\"),\n",
    "                MaxPooling2D(2),\n",
    "                Conv2D(cn, 3, activation=\"relu\", padding=\"same\"),\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    def call(self, x):\n",
    "        a = []\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "            if isinstance(l, Conv2D) and l.name != \"fcv\":\n",
    "                a.append(tf.reshape(x, [-1, tf.reduce_prod(x.shape[1:])]))\n",
    "        a = tf.concat(a, axis=1)\n",
    "        return a\n",
    "\n",
    "\n",
    "\n",
    "print(fh(4)(xr[:4]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(4, 18, 128)', '(4, 10)', '(4, 784)')\n"
     ]
    }
   ],
   "source": [
    "class fs(Sequential):\n",
    "    def __init__(self, ex, os):\n",
    "        super().__init__(\n",
    "            [\n",
    "                Dense(ex, activation=\"relu\"),\n",
    "                Dense(ex, activation=\"relu\"),\n",
    "                Dense(os),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "class ff(Sequential):\n",
    "    def __init__(self, ex, em):\n",
    "        super().__init__(\n",
    "            [\n",
    "                Dense(ex, activation=\"relu\"),\n",
    "                Dense(em),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "class tb(Layer):\n",
    "    def __init__(self, em, he, ex):\n",
    "        super().__init__()\n",
    "        self.at = MultiHeadAttention(he, em)\n",
    "        self.ff = ff(ex, em)\n",
    "        self.ad = Add()\n",
    "\n",
    "    def call(self, x): \n",
    "        ao = self.at(x, x)\n",
    "        ro = self.ad([x, ao])\n",
    "        fo = self.ff(ro)\n",
    "        return self.ad([ro, fo])\n",
    "\n",
    "class tm(Model):\n",
    "    def __init__(self, ly, em, he, ex, cl, at):\n",
    "        super().__init__()\n",
    "\n",
    "        self.em = ff(ex, em)\n",
    "\n",
    "        self.ct = self.add_weight(shape=(1, 1, em), name=\"ct\")\n",
    "        self.pt = self.add_weight(shape=(1, 1, em), name=\"pt\")\n",
    "\n",
    "        self.bl = []\n",
    "        for _ in range(ly):\n",
    "            self.bl.append(tb(em, he, ex))\n",
    "\n",
    "\n",
    "        self.ch = fs(ex, cl)\n",
    "        self.ph = fs(ex, at)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.em(x)\n",
    "        x = tf.concat([tf.tile(self.ct, [tf.shape(x)[0], 1, 1]), tf.tile(self.pt, [tf.shape(x)[0], 1, 1]), x], axis=1)\n",
    "        for b in self.bl:\n",
    "            x = b(x)\n",
    "        return x\n",
    "    \n",
    "    def cls(self, x):\n",
    "        return tf.nn.softmax(self.ch(self(x)[:, 0]), axis=1)\n",
    "\n",
    "    def plc(self, x):\n",
    "        return tf.nn.softmax(self.ph(self(x)[:, 1]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "print ((lambda model, x: (str(model(x).shape), str(model.cls(x).shape), str(model.plc(x).shape)))(tm(16, 128, 4, 256, 10, 784), tf.random.uniform((4, 16, 784))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ml(Model):\n",
    "    def __init__(self, ly=16, em=128, ex=256, he=4, cl=10, cn=4, sh=(28, 28, 1), il=16):\n",
    "        super().__init__()\n",
    "        self.fh = fh(cn)\n",
    "        at = sum(floor(sh[0]/2**i)*floor(sh[1]/2**i) for i in range(1, 3)) * cn\n",
    "        self.tm = tm(ly, em, he, ex, cl, at)\n",
    "        self.ip = self.add_weight(shape=(at, il), name=\"ip\")\n",
    "        self.at = at\n",
    "    def call(self, x):\n",
    "        ac = self.fh(x)\n",
    "        sip = tf.nn.softmax(self.ip, axis=0)\n",
    "        \n",
    "        ap = tf.concat([\n",
    "            tf.transpose(\n",
    "                tf.tile(\n",
    "                    tf.expand_dims(sip, 0), [tf.shape(x)[0], 1, 1]\n",
    "                    ), perm=[0, 2, 1]), \n",
    "            tf.expand_dims(tf.matmul(ac, sip), 2)\n",
    "            ], axis=2)\n",
    "        outs = []\n",
    "        for _ in range(8):\n",
    "            po = self.tm.plc(ap)\n",
    "            ns = tf.concat([tf.expand_dims(po, 1), tf.reshape(tf.einsum('ij,ij->i', ac, po), (-1, 1, 1))], axis=2)\n",
    "            ap = tf.concat([ap, ns], axis=1)\n",
    "            outs.append(self.tm.cls(ap))\n",
    "        out = tf.reduce_mean(tf.stack(outs), axis=0)\n",
    "        return out\n",
    "\n",
    "    def inf(self, x, r=1, q=False):\n",
    "        ac = self.fh(x)\n",
    "        sip = tf.nn.softmax(self.ip, axis=0)\n",
    "        if q:\n",
    "            sip = tf.transpose(zereno(tf.transpose(sip), k=32))\n",
    "        ap = tf.concat([\n",
    "            tf.transpose(\n",
    "                tf.tile(\n",
    "                    tf.expand_dims(sip, 0), [tf.shape(x)[0], 1, 1]\n",
    "                    ), perm=[0, 2, 1]), \n",
    "            tf.expand_dims(tf.matmul(ac, sip), 2)\n",
    "            ], axis=2)\n",
    "        outs = []\n",
    "        for _ in range(r):\n",
    "            po = self.tm.plc(ap)\n",
    "            if q:\n",
    "                po = zereno(po, k=20)\n",
    "            ns = tf.concat([tf.expand_dims(po, 1), tf.reshape(tf.einsum('ij,ij->i', ac, po), (-1, 1, 1))], axis=2)\n",
    "            ap = tf.concat([ap, ns], axis=1)\n",
    "            outs.append(self.tm.cls(ap))\n",
    "        return outs\n",
    "\n",
    "def zereno(softmax_batch, k=8):\n",
    "    # Find the indices of the top k elements in each softmax vector\n",
    "    top_k_indices = tf.math.top_k(softmax_batch, k=k).indices\n",
    "\n",
    "    # Create a mask to zero-out all but the top k elements in each vector\n",
    "    mask = tf.reduce_sum(tf.one_hot(top_k_indices, depth=tf.shape(softmax_batch)[-1]), axis=1)\n",
    "\n",
    "    # Zero-out all but the top k elements in each softmax vector\n",
    "    softmax_top_k = softmax_batch * mask\n",
    "\n",
    "    # Renormalize the modified softmax vectors\n",
    "    renormalized_softmax = softmax_top_k / tf.reduce_sum(softmax_top_k, axis=-1, keepdims=True)\n",
    "\n",
    "    return renormalized_softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "(64, 10)\n",
      "Model: \"ml_157\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fh_167 (fh)                 multiple                  1248      \n",
      "                                                                 \n",
      " tm_168 (tm)                 multiple                  153058    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,986\n",
      "Trainable params: 169,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ml(ly=4, em=16, ex=32, he=4, cl=10, cn=8, sh=(28, 28, 1), il=8)\n",
    "print(model(xr[:64]).shape)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf train\n",
    "\n",
    "cpc = keras.callbacks.ModelCheckpoint(filepath=\"train/cp.ckpt\", save_weights_only=True, verbose=1)\n",
    "model.save_weights('train/cp.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./logs/\n",
    "%load_ext tensorboard\n",
    "\n",
    "\n",
    "tbc = tf.keras.callbacks.TensorBoard(log_dir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.3297 - accuracy: 0.0800WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-27 12:56:03.089152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 94s 22s/step - loss: 2.3297 - accuracy: 0.0800 - val_loss: 2.3068 - val_accuracy: 0.0982\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.3023 - accuracy: 0.1080\n",
      "Epoch 2: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 48s 11s/step - loss: 2.3023 - accuracy: 0.1080 - val_loss: 2.3026 - val_accuracy: 0.1135\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2961 - accuracy: 0.1320\n",
      "Epoch 3: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 43s 10s/step - loss: 2.2961 - accuracy: 0.1320 - val_loss: 2.3037 - val_accuracy: 0.1135\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2951 - accuracy: 0.1320\n",
      "Epoch 4: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 39s 9s/step - loss: 2.2951 - accuracy: 0.1320 - val_loss: 2.3066 - val_accuracy: 0.1135\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2930 - accuracy: 0.1320\n",
      "Epoch 5: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 2.2930 - accuracy: 0.1320 - val_loss: 2.3059 - val_accuracy: 0.1135\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2924 - accuracy: 0.1320\n",
      "Epoch 6: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 8s/step - loss: 2.2924 - accuracy: 0.1320 - val_loss: 2.3060 - val_accuracy: 0.1135\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2929 - accuracy: 0.1320\n",
      "Epoch 7: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 8s/step - loss: 2.2929 - accuracy: 0.1320 - val_loss: 2.3068 - val_accuracy: 0.1135\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2928 - accuracy: 0.1320\n",
      "Epoch 8: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 8s/step - loss: 2.2928 - accuracy: 0.1320 - val_loss: 2.3075 - val_accuracy: 0.1135\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2926 - accuracy: 0.1320\n",
      "Epoch 9: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 8s/step - loss: 2.2926 - accuracy: 0.1320 - val_loss: 2.3067 - val_accuracy: 0.1135\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2926 - accuracy: 0.1320\n",
      "Epoch 10: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 8s/step - loss: 2.2926 - accuracy: 0.1320 - val_loss: 2.3069 - val_accuracy: 0.1135\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2925 - accuracy: 0.1320\n",
      "Epoch 11: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 8s/step - loss: 2.2925 - accuracy: 0.1320 - val_loss: 2.3060 - val_accuracy: 0.1135\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2922 - accuracy: 0.1320\n",
      "Epoch 12: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 8s/step - loss: 2.2922 - accuracy: 0.1320 - val_loss: 2.3053 - val_accuracy: 0.1135\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2920 - accuracy: 0.1320\n",
      "Epoch 13: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 8s/step - loss: 2.2920 - accuracy: 0.1320 - val_loss: 2.3052 - val_accuracy: 0.1135\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2928 - accuracy: 0.1320\n",
      "Epoch 14: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 9s/step - loss: 2.2928 - accuracy: 0.1320 - val_loss: 2.3053 - val_accuracy: 0.1135\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2921 - accuracy: 0.1320\n",
      "Epoch 15: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 2.2921 - accuracy: 0.1320 - val_loss: 2.3057 - val_accuracy: 0.1135\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2918 - accuracy: 0.1320\n",
      "Epoch 16: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 2.2918 - accuracy: 0.1320 - val_loss: 2.3053 - val_accuracy: 0.1135\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2919 - accuracy: 0.1320\n",
      "Epoch 17: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.2919 - accuracy: 0.1320 - val_loss: 2.3057 - val_accuracy: 0.1135\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2912 - accuracy: 0.1320\n",
      "Epoch 18: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.2912 - accuracy: 0.1320 - val_loss: 2.3048 - val_accuracy: 0.1135\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2910 - accuracy: 0.1320\n",
      "Epoch 19: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.2910 - accuracy: 0.1320 - val_loss: 2.3030 - val_accuracy: 0.1135\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2894 - accuracy: 0.1320\n",
      "Epoch 20: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.2894 - accuracy: 0.1320 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2874 - accuracy: 0.1320\n",
      "Epoch 21: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.2874 - accuracy: 0.1320 - val_loss: 2.2984 - val_accuracy: 0.1135\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2748 - accuracy: 0.1480\n",
      "Epoch 22: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 8s/step - loss: 2.2748 - accuracy: 0.1480 - val_loss: 2.2864 - val_accuracy: 0.1813\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.2518 - accuracy: 0.1900\n",
      "Epoch 23: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 35s 9s/step - loss: 2.2518 - accuracy: 0.1900 - val_loss: 2.2515 - val_accuracy: 0.1597\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.1794 - accuracy: 0.1880\n",
      "Epoch 24: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.1794 - accuracy: 0.1880 - val_loss: 2.1910 - val_accuracy: 0.2050\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.1085 - accuracy: 0.2180\n",
      "Epoch 25: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.1085 - accuracy: 0.2180 - val_loss: 2.1480 - val_accuracy: 0.2035\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 2.0155 - accuracy: 0.2540\n",
      "Epoch 26: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 2.0155 - accuracy: 0.2540 - val_loss: 2.0952 - val_accuracy: 0.2212\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.9243 - accuracy: 0.2580\n",
      "Epoch 27: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.9243 - accuracy: 0.2580 - val_loss: 2.0336 - val_accuracy: 0.2415\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8757 - accuracy: 0.2860\n",
      "Epoch 28: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.8757 - accuracy: 0.2860 - val_loss: 2.0085 - val_accuracy: 0.2422\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8815 - accuracy: 0.2560\n",
      "Epoch 29: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.8815 - accuracy: 0.2560 - val_loss: 1.9755 - val_accuracy: 0.2738\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.8463 - accuracy: 0.3040\n",
      "Epoch 30: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.8463 - accuracy: 0.3040 - val_loss: 1.9762 - val_accuracy: 0.2733\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7974 - accuracy: 0.3240\n",
      "Epoch 31: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.7974 - accuracy: 0.3240 - val_loss: 1.9124 - val_accuracy: 0.2865\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7611 - accuracy: 0.3220\n",
      "Epoch 32: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.7611 - accuracy: 0.3220 - val_loss: 1.9303 - val_accuracy: 0.2923\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.7229 - accuracy: 0.3580\n",
      "Epoch 33: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.7229 - accuracy: 0.3580 - val_loss: 1.8744 - val_accuracy: 0.3047\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.6608 - accuracy: 0.3440\n",
      "Epoch 34: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.6608 - accuracy: 0.3440 - val_loss: 1.8266 - val_accuracy: 0.3186\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.6259 - accuracy: 0.3660\n",
      "Epoch 35: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.6259 - accuracy: 0.3660 - val_loss: 1.8364 - val_accuracy: 0.3166\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.6060 - accuracy: 0.3860\n",
      "Epoch 36: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.6060 - accuracy: 0.3860 - val_loss: 1.8219 - val_accuracy: 0.3212\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5692 - accuracy: 0.4040\n",
      "Epoch 37: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 36s 9s/step - loss: 1.5692 - accuracy: 0.4040 - val_loss: 1.8094 - val_accuracy: 0.3285\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.6282 - accuracy: 0.3780\n",
      "Epoch 38: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.6282 - accuracy: 0.3780 - val_loss: 1.8804 - val_accuracy: 0.3095\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5852 - accuracy: 0.4020\n",
      "Epoch 39: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.5852 - accuracy: 0.4020 - val_loss: 1.7670 - val_accuracy: 0.3290\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5643 - accuracy: 0.4060\n",
      "Epoch 40: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.5643 - accuracy: 0.4060 - val_loss: 1.7684 - val_accuracy: 0.3511\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5415 - accuracy: 0.4080\n",
      "Epoch 41: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.5415 - accuracy: 0.4080 - val_loss: 1.8603 - val_accuracy: 0.3332\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5231 - accuracy: 0.4300\n",
      "Epoch 42: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.5231 - accuracy: 0.4300 - val_loss: 1.7666 - val_accuracy: 0.3396\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.5098 - accuracy: 0.4440\n",
      "Epoch 43: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 38s 9s/step - loss: 1.5098 - accuracy: 0.4440 - val_loss: 1.8332 - val_accuracy: 0.3394\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4902 - accuracy: 0.4440\n",
      "Epoch 44: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.4902 - accuracy: 0.4440 - val_loss: 1.7577 - val_accuracy: 0.3523\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4568 - accuracy: 0.4560\n",
      "Epoch 45: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.4568 - accuracy: 0.4560 - val_loss: 1.7990 - val_accuracy: 0.3420\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4249 - accuracy: 0.4420\n",
      "Epoch 46: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.4249 - accuracy: 0.4420 - val_loss: 1.7860 - val_accuracy: 0.3589\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4411 - accuracy: 0.4680\n",
      "Epoch 47: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.4411 - accuracy: 0.4680 - val_loss: 1.7516 - val_accuracy: 0.3638\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.4000 - accuracy: 0.5040\n",
      "Epoch 48: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.4000 - accuracy: 0.5040 - val_loss: 1.8133 - val_accuracy: 0.3735\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3947 - accuracy: 0.4600\n",
      "Epoch 49: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.3947 - accuracy: 0.4600 - val_loss: 1.7194 - val_accuracy: 0.3736\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 1.3740 - accuracy: 0.4920\n",
      "Epoch 50: saving model to train/cp.ckpt\n",
      "5/5 [==============================] - 37s 9s/step - loss: 1.3740 - accuracy: 0.4920 - val_loss: 1.7143 - val_accuracy: 0.3904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x371a7d8d0>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('train/cp.ckpt')\n",
    "\n",
    "model.fit(\n",
    "    xr[:500], yr[:500],\n",
    "    epochs=50,\n",
    "    validation_data=(xe, ye),\n",
    "    callbacks=[cpc, tbc],\n",
    "    batch_size=100,\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " normal  37.12 %\n",
      " qant  21.81 %\n",
      " qant  27.15 %\n",
      " qant  31.64 %\n",
      " qant  34.77 %\n",
      " qant  36.5 %\n",
      " qant  37.73 %\n",
      " qant  38.22 %\n",
      " qant  38.38 %\n",
      " qant  38.59 %\n",
      " qant  38.69 %\n",
      " qant  38.69 %\n",
      " qant  38.77 %\n",
      " qant  38.88 %\n",
      " qant  38.94 %\n",
      " qant  39.07 %\n",
      " qant  39.42 %\n",
      " qant  39.49 %\n",
      " qant  39.71 %\n",
      " qant  39.69 %\n",
      " qant  39.82 %\n",
      " qant  39.79 %\n",
      " qant  39.84 %\n",
      " qant  39.91 %\n",
      " qant  39.97 %\n",
      " qant  39.89 %\n",
      " qant  39.86 %\n",
      " qant  39.89 %\n",
      " qant  39.84 %\n",
      " qant  39.81 %\n",
      " qant  39.79 %\n",
      " qant  39.8 %\n",
      " qant  39.8 %\n",
      " fuzz  24.35 %\n",
      " fuzz  30.55 %\n",
      " fuzz  33.95 %\n",
      " fuzz  36.43 %\n",
      " fuzz  38.22 %\n",
      " fuzz  39.12 %\n",
      " fuzz  40.07 %\n",
      " fuzz  40.64 %\n",
      " fuzz  41.05 %\n",
      " fuzz  41.12 %\n",
      " fuzz  41.26 %\n",
      " fuzz  41.49 %\n",
      " fuzz  41.41 %\n",
      " fuzz  41.57 %\n",
      " fuzz  41.63 %\n",
      " fuzz  41.78 %\n",
      " fuzz  41.74 %\n",
      " fuzz  41.74 %\n",
      " fuzz  41.87 %\n",
      " fuzz  41.77 %\n",
      " fuzz  41.74 %\n",
      " fuzz  41.68 %\n",
      " fuzz  41.85 %\n",
      " fuzz  41.91 %\n",
      " fuzz  41.79 %\n",
      " fuzz  41.8 %\n",
      " fuzz  41.81 %\n",
      " fuzz  41.79 %\n",
      " fuzz  41.61 %\n",
      " fuzz  41.6 %\n",
      " fuzz  41.56 %\n",
      " fuzz  41.57 %\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('train/cp.ckpt')\n",
    "print(\" normal \", round(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(model(xe), axis=1), tf.argmax(ye, axis=1)), tf.float32)).numpy()*100, 3), \"%\")\n",
    "\n",
    "for out in model.inf(xe, r=32, q=True):\n",
    "    print(\" qant \", round(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, axis=1), tf.argmax(ye, axis=1)), tf.float32)).numpy()*100, 3), \"%\")\n",
    "for out in model.inf(xe, r=32, q=False):\n",
    "    print(\" fuzz \", round(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(out, axis=1), tf.argmax(ye, axis=1)), tf.float32)).numpy()*100, 3), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ec3d5075bc4536d6\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ec3d5075bc4536d6\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
