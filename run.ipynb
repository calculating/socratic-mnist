{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 1/50 [..............................] - ETA: 14s - loss: 2.3180 - accuracy: 0.1030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 11:40:24.601188: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 23ms/step - loss: 2.2722 - accuracy: 0.1487 - val_loss: 2.1761 - val_accuracy: 0.2072\n",
      "Epoch 2/2\n",
      " 1/50 [..............................] - ETA: 0s - loss: 2.1698 - accuracy: 0.1930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 11:40:25.718798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 1s 18ms/step - loss: 1.9793 - accuracy: 0.2797 - val_loss: 1.8655 - val_accuracy: 0.3281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 11:40:26.917098: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 3s - loss: 1.8655 - accuracy: 0.3281 - 3s/epoch - 8ms/step\n",
      "\n",
      "Test accuracy: 0.3280999958515167\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Layer 1 activation shape: (1, 32, 32, 3)\n",
      "Layer 2 activation shape: (1, 30, 30, 8)\n",
      "Layer 3 activation shape: (1, 15, 15, 8)\n",
      "Layer 4 activation shape: (1, 13, 13, 8)\n",
      "Layer 5 activation shape: (1, 6, 6, 8)\n",
      "Layer 6 activation shape: (1, 4, 4, 8)\n",
      "Layer 7 activation shape: (1, 128)\n",
      "Layer 8 activation shape: (1, 10)\n",
      "Total activations for a single image: 13978\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "tf.Tensor(\n",
      "[0.25490198 0.31761384 0.858051   0.12029882 0.7586678  0.03061792\n",
      " 0.         0.68235296 0.716138   0.20148279], shape=(10,), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 11:40:29.507552: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n",
    "\n",
    "\n",
    "class SimpleCNN(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = self.build_model()\n",
    "        # dont include the final output layer\n",
    "        self.activation_model = Model(inputs=self.model.input, outputs=[layer.output for layer in self.model.layers[:-1]])\n",
    "\n",
    "    def build_model(self):\n",
    "        inputs = Input(shape=(32, 32, 3))\n",
    "        x = layers.Conv2D(8, 3, activation='relu')(inputs)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.Conv2D(8, 3, activation='relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.Conv2D(8, 3, activation='relu')(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        outputs = layers.Dense(10, activation='softmax')(x)\n",
    "        return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def get_activations(self, x):\n",
    "        return self.activation_model.predict(x)\n",
    "\n",
    "    def get_specific_activations(self, x, activation_indices):\n",
    "        activations = self.get_activations(x)\n",
    "        flattened_activations = tf.concat([tf.reshape(a, [-1]) for a in activations], axis=0)\n",
    "        return tf.gather(flattened_activations, activation_indices)\n",
    "\n",
    "\n",
    "model = SimpleCNN()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=1000, epochs=2, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "activations = model.get_activations(x_test[0:1])\n",
    "for i, activation in enumerate(activations):\n",
    "    print(f'Layer {i+1} activation shape: {activation.shape}')\n",
    "\n",
    "total_activations = sum(a.size for a in activations)\n",
    "print('Total activations for a single image:', total_activations)\n",
    "\n",
    "# 10 random integers between 0 and total_activations\n",
    "print(model.get_specific_activations(x_test[0:1], [random.randint(0, total_activations) for _ in range(10)]))\n",
    "\n",
    "class BaseAttention(layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = layers.LayerNormalization()\n",
    "    self.add = layers.Add()\n",
    "\n",
    "class GSA(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x\n",
    "\n",
    "class FeedForward(layers.Layer):\n",
    "  def __init__(self, d_model, dff):\n",
    "    super().__init__()\n",
    "    self.seq = models.Sequential([\n",
    "      layers.Dense(dff, activation='relu'),\n",
    "      layers.Dense(d_model)\n",
    "    ])\n",
    "    self.add = layers.Add()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    return x\n",
    "\n",
    "class TransformLayer(layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GSA(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x\n",
    "\n",
    "class Transformer(Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff):\n",
    "    super().__init__()\n",
    "    self.embedder = layers.Dense(d_model)\n",
    "    self.layerstack = [TransformLayer(d_model=d_model, num_heads=num_heads, dff=dff) for _ in range(num_layers)]\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.embedder(x)\n",
    "    for layer in self.layerstack:\n",
    "        x = layer(x)\n",
    "    return x\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
