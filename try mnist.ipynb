{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import Layer, Input, Dense, Conv2D, MaxPooling2D, Flatten, MultiHeadAttention, Add, Lambda\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()\n",
    "xTrain, xTest = xTrain / 255.0, xTest / 255.0\n",
    "yTrain, yTest = to_categorical(yTrain), to_categorical(yTest)\n",
    "# expand images to 1 channel\n",
    "xTrain = np.expand_dims(xTrain, axis=-1)\n",
    "xTest = np.expand_dims(xTest, axis=-1)\n",
    "\n",
    "_, boxes = plt.subplots(1, 5, figsize=(8, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    index = random.randint(0, len(xTrain))\n",
    "    box.imshow(xTrain[index])\n",
    "    box.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterHeap(ch=8):\n",
    "    return Sequential(\n",
    "        [\n",
    "            Conv2D(ch, 3, activation=\"relu\"),\n",
    "            MaxPooling2D(2),\n",
    "            Conv2D(ch, 3, activation=\"relu\"),\n",
    "            MaxPooling2D(2),\n",
    "            Conv2D(ch, 3, activation=\"relu\"),\n",
    "            Flatten(),\n",
    "            Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed, heads, expand):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=heads, key_dim=embed)\n",
    "        self.ffn = Sequential(\n",
    "            [layers.Dense(expand, activation=\"relu\"), layers.Dense(embed)]\n",
    "        )\n",
    "        self.add = layers.Add()\n",
    "\n",
    "    def call(self, inputs): \n",
    "        att_out = self.att(inputs, inputs)\n",
    "        res_out = self.add([inputs, att_out])\n",
    "        ffn_out = self.ffn(res_out)\n",
    "        return self.add([res_out, ffn_out])\n",
    "\n",
    "\n",
    "class TransformerModel(Model):\n",
    "    def __init__(self, layers=16, embed=128, heads=4, expand=256, classes=10, activations=10906):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedder = Sequential(\n",
    "            [\n",
    "                Dense(expand, activation=\"relu\"),\n",
    "                Dense(embed, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.class_token = self.add_weight(shape=(1, 1, embed), initializer=\"zeros\", trainable=True)\n",
    "        self.policy_token = self.add_weight(shape=(1, 1, embed), initializer=\"zeros\", trainable=True)\n",
    "\n",
    "        self.blocks = []\n",
    "        for _ in range(layers):\n",
    "            self.blocks.append(TransformerBlock(embed, heads, expand))\n",
    "\n",
    "\n",
    "        self.classification_head = Sequential(\n",
    "            [\n",
    "                Dense(expand, activation=\"relu\"),\n",
    "                Dense(expand, activation=\"relu\"),\n",
    "                Dense(classes, activation=\"softmax\"),\n",
    "            ]\n",
    "        )\n",
    "        self.policy_head = Sequential(\n",
    "            [\n",
    "                Dense(expand, activation=\"relu\"),\n",
    "                Dense(expand, activation=\"relu\"),\n",
    "                Dense(activations, activation=\"softmax\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedder(inputs)\n",
    "        # prepend the class and policy tokens to the embedded sequence, duplicating for the batch\n",
    "        x = tf.concat([tf.tile(self.class_token, [tf.shape(x)[0], 1, 1]), x], axis=1)\n",
    "        x = tf.concat([tf.tile(self.policy_token, [tf.shape(x)[0], 1, 1]), x], axis=1)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        # pass the class token to the classification head, and the policy token to the policy head\n",
    "        return self.classification_head(x[:, 0]), self.policy_head(x[:, 1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Max\n",
      "\n",
      "systemMemory: 96.00 GB\n",
      "maxCacheSize: 36.00 GB\n",
      "\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:25:20.904843: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-04-26 11:25:20.905314: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-04-26 11:25:21.107565: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/15 [=>............................] - ETA: 6s - loss: 2.3131 - accuracy: 0.0815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:25:21.355671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 34ms/step - loss: 2.2699 - accuracy: 0.1889 - val_loss: 2.2186 - val_accuracy: 0.2848\n",
      "Epoch 2/4\n",
      " 4/15 [=======>......................] - ETA: 0s - loss: 2.2113 - accuracy: 0.2950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:25:21.928415: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 22ms/step - loss: 2.1555 - accuracy: 0.3637 - val_loss: 2.0460 - val_accuracy: 0.4645\n",
      "Epoch 3/4\n",
      "15/15 [==============================] - 0s 21ms/step - loss: 1.9033 - accuracy: 0.5290 - val_loss: 1.6703 - val_accuracy: 0.5967\n",
      "Epoch 4/4\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 1.4412 - accuracy: 0.6681 - val_loss: 1.1374 - val_accuracy: 0.7277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c60612d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision = FilterHeap(8)\n",
    "\n",
    "vision.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "vision.fit(xTrain, yTrain, epochs=4, batch_size=4000, validation_data=(xTest, yTest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 16, 8083)\n",
      "(500, 10)\n",
      "(500, 16, 8083)\n",
      "(500, 10)\n",
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def GetActivations(model, inputs):\n",
    "    activations = []\n",
    "    for layer in model.layers:\n",
    "        inputs = layer(inputs)\n",
    "        activations.append(tf.reshape(inputs, [inputs.shape[0], -1]))\n",
    "    activations = tf.concat(activations, axis=1)\n",
    "    return activations\n",
    "\n",
    "\n",
    "def SampleSequence(activations, indices):\n",
    "    sequence = tf.concat([\n",
    "        tf.one_hot(indices, activations.shape[1]),\n",
    "        tf.expand_dims(tf.gather(activations, indices, axis=1, batch_dims=1), axis=2)\n",
    "    ], axis=2)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def generator(images, labels, batch_size=500):\n",
    "    num_samples = len(images)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        x_batch = images[i:i + batch_size]\n",
    "        y_batch = labels[i:i + batch_size]\n",
    "        activations_batch = GetActivations(vision, x_batch)\n",
    "        act_sequence = SampleSequence(activations_batch, tf.random.uniform([batch_size, s_len], maxval=a_num, dtype=tf.int32))\n",
    "        yield act_sequence, y_batch\n",
    "\n",
    "a_num = GetActivations(vision, xTrain[:1]).shape[1]\n",
    "s_len = 16\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    args=(xTrain, yTrain),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, s_len, a_num+1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 10), dtype=tf.uint8)\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    args=(xTest, yTest),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, s_len, a_num+1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 10), dtype=tf.uint8)\n",
    "    )\n",
    ")\n",
    "\n",
    "for x, y in train_dataset.take(2):\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "print(xTrain.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "seq_len = 64\n",
    "trainN = 8000\n",
    "testN = 500\n",
    "\n",
    "sequence_train = SampleSequence(\n",
    "    GetActivations(vision, xTrain[:trainN]),\n",
    "    tf.random.uniform([trainN, seq_len], maxval=a_num, dtype=tf.int32)\n",
    ")\n",
    "\n",
    "sequence_test = SampleSequence(\n",
    "    GetActivations(vision, xTest[:testN]),\n",
    "    tf.random.uniform([testN, seq_len], maxval=a_num, dtype=tf.int32)\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learner = TransformerModel(layers=8, embed=128, heads=4, expand=256, classes=10, activations=a_num)\n",
    "\n",
    "learner.compile(optimizer='adam',\n",
    "            loss=[keras.losses.CategoricalCrossentropy(), None],\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'dense_24/kernel:0', 'dense_24/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'dense_24/kernel:0', 'dense_24/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:25:47.113788: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    120/Unknown - 198s 2s/step - loss: 2.3067 - output_1_loss: 2.3067 - output_1_accuracy: 0.1078 - output_2_accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:29:03.641308: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 207s 2s/step - loss: 2.3067 - output_1_loss: 2.3067 - output_1_accuracy: 0.1078 - output_2_accuracy: 0.0000e+00 - val_loss: 2.3012 - val_output_1_loss: 2.3012 - val_output_1_accuracy: 0.1135 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - 202s 2s/step - loss: 2.2835 - output_1_loss: 2.2835 - output_1_accuracy: 0.1359 - output_2_accuracy: 0.0000e+00 - val_loss: 2.2497 - val_output_1_loss: 2.2497 - val_output_1_accuracy: 0.1593 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - 205s 2s/step - loss: 2.2037 - output_1_loss: 2.2037 - output_1_accuracy: 0.1832 - output_2_accuracy: 0.0000e+00 - val_loss: 2.1619 - val_output_1_loss: 2.1619 - val_output_1_accuracy: 0.1997 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - 204s 2s/step - loss: 2.1564 - output_1_loss: 2.1564 - output_1_accuracy: 0.2019 - output_2_accuracy: 0.0000e+00 - val_loss: 2.1093 - val_output_1_loss: 2.1093 - val_output_1_accuracy: 0.2207 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - 205s 2s/step - loss: 2.1124 - output_1_loss: 2.1124 - output_1_accuracy: 0.2236 - output_2_accuracy: 0.0000e+00 - val_loss: 2.0727 - val_output_1_loss: 2.0727 - val_output_1_accuracy: 0.2365 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - 207s 2s/step - loss: 2.0484 - output_1_loss: 2.0484 - output_1_accuracy: 0.2518 - output_2_accuracy: 0.0000e+00 - val_loss: 2.0001 - val_output_1_loss: 2.0001 - val_output_1_accuracy: 0.2714 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - 207s 2s/step - loss: 1.9713 - output_1_loss: 1.9713 - output_1_accuracy: 0.2798 - output_2_accuracy: 0.0000e+00 - val_loss: 1.9488 - val_output_1_loss: 1.9488 - val_output_1_accuracy: 0.2858 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - 205s 2s/step - loss: 1.9227 - output_1_loss: 1.9227 - output_1_accuracy: 0.2974 - output_2_accuracy: 0.0000e+00 - val_loss: 1.8861 - val_output_1_loss: 1.8861 - val_output_1_accuracy: 0.3127 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - 206s 2s/step - loss: 1.8816 - output_1_loss: 1.8816 - output_1_accuracy: 0.3150 - output_2_accuracy: 0.0000e+00 - val_loss: 1.8545 - val_output_1_loss: 1.8545 - val_output_1_accuracy: 0.3334 - val_output_2_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - 205s 2s/step - loss: 1.8363 - output_1_loss: 1.8363 - output_1_accuracy: 0.3357 - output_2_accuracy: 0.0000e+00 - val_loss: 1.8220 - val_output_1_loss: 1.8220 - val_output_1_accuracy: 0.3350 - val_output_2_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c606f730>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "learner.fit(train_dataset, epochs=10, validation_data=(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['dense_22/kernel:0', 'dense_22/bias:0', 'dense_23/kernel:0', 'dense_23/bias:0', 'dense_24/kernel:0', 'dense_24/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 11:59:58.384526: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    120/Unknown - 208s 2s/step - loss: 1.7770 - output_1_loss: 1.7770 - output_1_accuracy: 0.3573 - output_2_accuracy: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 12:03:25.692137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 217s 2s/step - loss: 1.7770 - output_1_loss: 1.7770 - output_1_accuracy: 0.3573 - output_2_accuracy: 0.0000e+00 - val_loss: 1.7507 - val_output_1_loss: 1.7507 - val_output_1_accuracy: 0.3703 - val_output_2_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x35e857f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_num = GetActivations(vision, xTrain[:1]).shape[1]\n",
    "s_len = 17\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    args=(xTrain, yTrain),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, s_len, a_num+1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 10), dtype=tf.uint8)\n",
    "    )\n",
    ")\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    generator,\n",
    "    args=(xTest, yTest),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, s_len, a_num+1), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 10), dtype=tf.uint8)\n",
    "    )\n",
    ")\n",
    "\n",
    "learner.fit(train_dataset, epochs=1, validation_data=(test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
